{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "@Author:Vijay Kumar M N<br>\n",
    "@Date: 2024-10-24<br>\n",
    "@Last Modified by:Vijay Kumar M N<br>\n",
    "@Last Modified: 2024-10-24<br>\n",
    "@Title :Python Program to interact with rds and import and export<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to employees_export.csv\n",
      "File uploaded to S3: backupsql1/employees_export.csv\n"
     ]
    }
   ],
   "source": [
    "import pymssql\n",
    "import csv\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch credentials from the environment\n",
    "AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "AWS_REGION = os.getenv('AWS_DEFAULT_REGION')\n",
    "\n",
    "# Function to connect to MSSQL RDS\n",
    "def connect_to_database(endpoint, port, username, password, database):\n",
    "    conn = pymssql.connect(server=f\"{endpoint}:{port}\", user=username, password=password, database=database)\n",
    "    return conn\n",
    "\n",
    "# Function to export data from MSSQL to a CSV file\n",
    "def export_data_to_csv(conn, table_name, csv_file):\n",
    "    cursor = conn.cursor()\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    # Write data to CSV\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([i[0] for i in cursor.description])  # Write headers\n",
    "        writer.writerows(cursor.fetchall())  # Write data\n",
    "    \n",
    "    print(f\"Data exported to {csv_file}\")\n",
    "\n",
    "# Function to upload the CSV file to S3\n",
    "def upload_file_to_s3(file_name, bucket_name, s3_file_name):\n",
    "    # Initialize the boto3 client using environment credentials\n",
    "    s3 = boto3.client('s3',\n",
    "                      aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                      aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "                      region_name=AWS_REGION)\n",
    "\n",
    "    try:\n",
    "        s3.upload_file(file_name, bucket_name, s3_file_name)\n",
    "        print(f\"File uploaded to S3: {bucket_name}/{s3_file_name}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found.\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"AWS credentials not available.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # MSSQL RDS connection details\n",
    "    endpoint = 'database-1.c3e2sig42eps.ap-south-1.rds.amazonaws.com'\n",
    "    port = 1433\n",
    "    username = 'admin'\n",
    "    password = 'vijaykumar123'\n",
    "    database = 'vijayvk'\n",
    "\n",
    "    # CSV and S3 details\n",
    "    table_name = 'Employees'\n",
    "    csv_file = 'employees_export.csv'\n",
    "    bucket_name = 'backupsql1'\n",
    "    s3_file_name = 'employees_export.csv'\n",
    "\n",
    "    # Connect to MSSQL and export data to CSV\n",
    "    conn = connect_to_database(endpoint, port, username, password, database)\n",
    "    try:\n",
    "        export_data_to_csv(conn, table_name, csv_file)\n",
    "        \n",
    "        # Upload the CSV to S3\n",
    "        upload_file_to_s3(csv_file, bucket_name, s3_file_name)\n",
    "    finally:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects in backupsql1:\n",
      "employees_export.csv\n",
      "File downloaded from S3: employees_export.csv\n",
      "Data imported from C:/Users/vijay/OneDrive/Desktop/sql/employees_import.csv\n"
     ]
    }
   ],
   "source": [
    "AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "AWS_REGION = os.getenv('AWS_DEFAULT_REGION')\n",
    "\n",
    "# Function to connect to MSSQL RDS\n",
    "def connect_to_database(endpoint, port, username, password, database):\n",
    "    conn = pymssql.connect(server=f\"{endpoint}:{port}\", user=username, password=password, database=database)\n",
    "    return conn\n",
    "\n",
    "# Function to download CSV from S3\n",
    "def download_file_from_s3(bucket_name, s3_file_name, local_file_name):\n",
    "    s3 = boto3.client('s3',\n",
    "                      aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                      aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "                      region_name=AWS_REGION)\n",
    "    try:\n",
    "        s3.download_file(bucket_name, s3_file_name, local_file_name)\n",
    "        print(f\"File downloaded from S3: {s3_file_name}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found.\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "\n",
    "# Function to import data from CSV into MSSQL\n",
    "def import_data_from_csv(conn, table_name, csv_file):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        headers = next(reader)  # Get header row\n",
    "        num_columns = len(headers)  # Count columns\n",
    "\n",
    "        for row in reader:\n",
    "            if len(row) != num_columns:  # Ensure row matches header length\n",
    "                print(f\"Skipping row due to mismatched column count: {row}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Assuming the first column is the primary key, adjust column names if necessary\n",
    "                cursor.execute(f\"\"\"\n",
    "                    IF NOT EXISTS (SELECT * FROM {table_name} WHERE id = %s)  -- Replace 'id' with your primary key column name\n",
    "                    BEGIN\n",
    "                        INSERT INTO {table_name} VALUES ({', '.join(['%s'] * num_columns)})  -- Use the correct number of placeholders\n",
    "                    END\n",
    "                \"\"\", (row[0],) + tuple(row))  # Adjust this based on your primary key and number of columns\n",
    "            except pymssql.IntegrityError as e:\n",
    "                print(f\"Duplicate entry for primary key {row[0]}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error inserting row {row}: {e}\")\n",
    "\n",
    "    conn.commit()\n",
    "    print(f\"Data imported from {csv_file}\")\n",
    "\n",
    "# Function to list objects in the S3 bucket for troubleshooting\n",
    "def list_objects_in_s3(bucket_name):\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "    if 'Contents' in response:\n",
    "        print(f\"Objects in {bucket_name}:\")\n",
    "        for obj in response['Contents']:\n",
    "            print(obj['Key'])\n",
    "    else:\n",
    "        print(\"Bucket is empty or does not exist.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # MSSQL RDS connection details\n",
    "    endpoint = 'database-1.c3e2sig42eps.ap-south-1.rds.amazonaws.com'\n",
    "    port = 1433\n",
    "    username = 'admin'\n",
    "    password = 'vijaykumar123'\n",
    "    database = 'vijayvk'\n",
    "\n",
    "    # S3 and CSV details\n",
    "    bucket_name = 'backupsql1'\n",
    "    s3_file_name = 'employees_export.csv'\n",
    "    local_file_name = 'C:/Users/vijay/OneDrive/Desktop/sql/employees_import.csv'  # Adjust path if needed\n",
    "    table_name = 'Employees1'\n",
    "\n",
    "    # List objects in S3 for troubleshooting\n",
    "    list_objects_in_s3(bucket_name)\n",
    "\n",
    "    # Download CSV from S3\n",
    "    download_file_from_s3(bucket_name, s3_file_name, local_file_name)\n",
    "\n",
    "    # Check if the file exists before importing\n",
    "    if os.path.exists(local_file_name):\n",
    "        # Connect to MSSQL and import data from CSV\n",
    "        conn = connect_to_database(endpoint, port, username, password, database)\n",
    "        try:\n",
    "            import_data_from_csv(conn, table_name, local_file_name)\n",
    "        finally:\n",
    "            conn.close()\n",
    "    else:\n",
    "        print(f\"File {local_file_name} not found after download.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fcbd7240ee8f908d933dc7f71e8c42a1a91163b70ede8dcff5146d4087436c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
